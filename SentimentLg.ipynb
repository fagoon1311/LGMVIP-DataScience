{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM01QKl/GLu04o7kbJcOy7d",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fagoon1311/LGMVIP-DataScience/blob/main/SentimentLg.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "CNRlnBI6Gset"
      },
      "outputs": [],
      "source": [
        "import nltk, re, string\n",
        "from nltk.corpus import stopwords, twitter_samples\n",
        "import numpy as np\n",
        "import pickle"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def process_tweet(tweet):\n",
        "  stemmer = nltk.PorterStemmer()\n",
        "  stopwords_english = stopwords.words('english')\n",
        "  tweet = re.sub(r'\\$\\w*', '', tweet)\n",
        "  #The \"$\" character in the regular expression is used to match the \"$\" symbol, and \"\\w*\" is used to match any word character (letters, digits, or underscore) zero or more \n",
        "  #times after the \"$\" symbol.\n",
        "  #So, the regular expression \"$\\w*\" matches any word starting with a \"$\" symbol, such as $BTC or $ETH.\n",
        "  tweet = re.sub(r'^RT[\\s]+','', tweet)\n",
        "  #The \"^\" character in the regular expression is used to match the start of the string, so this pattern only matches \"RT\" if it is at the beginning of the string. \n",
        "  #The \"[\\s]+\" pattern matches one or more \n",
        "  #whitespace characters (including spaces, tabs, and line breaks) that follow the \"RT\" sequence.\n",
        "  tweet = re.sub(r'https?:\\/\\/.*[\\r\\n]*','', tweet)\n",
        "  #The regular expression pattern starts with \"https?://\" which matches \"http://\" or \"https://\". The \"s?\" indicates that the \"s\" character is optional. \n",
        "  #Then, \".*\" matches any character zero or more times (except for new line characters), until the end of the URL is reached (which is indicated by a space or a line break).\n",
        "\n",
        "  #The \"[\\r\\n]*\" pattern at the end of the regular expression matches any number of carriage return (\"\\r\") or newline (\"\\n\") characters that may follow the URL.\n",
        "  tweet = re.sub(r'#','', tweet)\n",
        "  tokenizer = nltk.TweetTokenizer(preserve_case=False, strip_handles=True, reduce_len=True)\n",
        "  tweet_tokens = tokenizer.tokenize(tweet)\n",
        "\n",
        "  tweets_clean = []\n",
        "  for word in tweet_tokens:\n",
        "    if (word not in stopwords_english and word not in string.punctuation):\n",
        "      stem_word = stemmer.stem(word)\n",
        "      tweets_clean.append(stem_word)\n",
        "  return tweets_clean"
      ],
      "metadata": {
        "id": "Cm0xSD3LG6Xf"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_freqs(tweets, ys):\n",
        "  \"\"\"\n",
        "  build Frequencies\n",
        "  Input: \n",
        "  tweets - a list of tweets\n",
        "  ys - an mx1 array with sentiment label of each tweet\n",
        "\n",
        "  Output:\n",
        "  Freqs: a dictionary mapping each word, sentiment pair to its frequency\n",
        "\n",
        "  \"\"\"\n",
        "  # convert np array to list since zip needs an iterable\n",
        "  # The sequence is neccesary or the list ends up with one element\n",
        "  # Also note that this is just a NOP if ys is already a list\n",
        "  yslist = np.squeeze(ys).tolist()\n",
        "\n",
        "  # Start with an empty dictionary and populate it with looping over all tweets\n",
        "  # and over all processed words in each tweet.\n",
        "  freqs = {}\n",
        "  for y, tweet in zip(yslist, tweets):\n",
        "    for word in process_tweet(tweet):\n",
        "      pair = (word, y)\n",
        "      if pair in freqs:\n",
        "        freqs[pair] += 1\n",
        "      else:\n",
        "        freqs[pair] = 1\n",
        "  return freqs"
      ],
      "metadata": {
        "id": "K8qfw2WdNkPS"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('twitter_samples')\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sB6VItkzQjGt",
        "outputId": "d902b268-dc41-47dd-9762-d5aec8b0ebd6"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package twitter_samples to /root/nltk_data...\n",
            "[nltk_data]   Package twitter_samples is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking the above code with an example.\n",
        "tweets = ['i am happy', 'i am tricked', 'i am sad', 'i am tired', 'i am tired']\n",
        "ys = [1,0,0,0,0]\n",
        "res = build_freqs(tweets, ys)\n",
        "print(res)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NLP1189jPmeP",
        "outputId": "5e242d98-8440-407f-8c7b-21f2d6795e11"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{('happi', 1): 1, ('trick', 0): 1, ('sad', 0): 1, ('tire', 0): 2}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# select theset of + and - tweets\n",
        "all_positive_tweets = twitter_samples.strings('positive_tweets.json')\n",
        "all_negative_tweets = twitter_samples.strings('negative_tweets.json')"
      ],
      "metadata": {
        "id": "tBy4j-MLP-6c"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# splitting data into 2 pieces to train and test\n",
        "test_pos = all_positive_tweets[4000:]\n",
        "train_pos = all_positive_tweets[:4000]\n",
        "test_neg = all_negative_tweets[4000:]\n",
        "train_neg = all_negative_tweets[:4000]"
      ],
      "metadata": {
        "id": "JrAgIAaHRMer"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_x = train_pos + train_neg\n",
        "test_x = test_pos + test_neg"
      ],
      "metadata": {
        "id": "GRkjel2eRn5q"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# combine postive and negative labels\n",
        "# we are building our y- target variable here\n",
        "train_y = np.append(np.ones((len(train_pos), 1)), np.zeros((len(train_neg), 1)), axis=0)\n",
        "test_y = np.append(np.ones((len(test_pos), 1)), np.zeros((len(test_neg), 1)), axis=0)"
      ],
      "metadata": {
        "id": "4FOI11kmRxac"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create frequency dictionary\n",
        "freqs = build_freqs(train_x, train_y)"
      ],
      "metadata": {
        "id": "dLzoZs8DSvq-"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# checking the op\n",
        "print(\"type(freqs = \" + str(type(freqs)))\n",
        "print(\"len(freqs) = \" + str(len(freqs.keys())))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lpV4IBYjTPvd",
        "outputId": "6f1c33e2-5b51-4ea8-954b-f19264907d03"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "type(freqs = <class 'dict'>\n",
            "len(freqs) = 11337\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TEST THE FN BELOW\n",
        "print('This is an example of a positive tweet: \\n', train_x[22])\n",
        "print('\\nThis is an example of processed version of the tweet: \\n', process_tweet(train_x[22]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BppJ7cZDTpch",
        "outputId": "2ec653c4-0fc3-4117-b523-bdbd36596ef8"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This is an example of a positive tweet: \n",
            " @gculloty87 Yeah I suppose she was lol! Chat in a bit just off out x :))\n",
            "\n",
            "This is an example of processed version of the tweet: \n",
            " ['yeah', 'suppos', 'lol', 'chat', 'bit', 'x', ':)']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# building a logistic model from the scratch\n",
        "# Logistic Func\n",
        "# sigmoid Function\n",
        "def sigmoid(z):\n",
        "  zz = np.negative(z)\n",
        "  h = 1/(1+np.exp(zz))\n",
        "  return h"
      ],
      "metadata": {
        "id": "84mDawGRUHet"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def gradientDescent(x, y, theta, alpha, num_iters):\n",
        "  m = x.shape[0]\n",
        "  for i in range(0, num_iters):\n",
        "    z = np.dot(x, theta)\n",
        "    h = sigmoid(z)\n",
        "    cost = -1./m* (np.dot(y.transpose(), np.log(h)) + np.dot((1-y).transpose(), np.log(1 - h)))\n",
        "    theta = theta - (alpha/m) * np.dot(x.transpose(), (h - y))\n",
        "  cost = float(cost)\n",
        "  return cost, theta\n",
        "\n"
      ],
      "metadata": {
        "id": "QJapj4Y8VhBq"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# extracted the features\n",
        "def extract_features(tweet, freqs):\n",
        "  word_1 = process_tweet(tweet)\n",
        "  x = np.zeros((1,3))\n",
        "  x[0,0]=1\n",
        "  for word in word_1:\n",
        "    # increment the word count for the positive label 1\n",
        "    x[0,1] += freqs.get((word, 1.0), 0)\n",
        "    # increment the word count for the negative label 0\n",
        "    x[0,2] += freqs.get((word, 0.0), 0)\n",
        "\n",
        "  assert(x.shape == (1,3))\n",
        "  return x "
      ],
      "metadata": {
        "id": "lDDOn8caXVu9"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test on training data\n",
        "tmp1 = extract_features(train_x[22], freqs)\n",
        "print(tmp1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ajCRPa8ZYyGu",
        "outputId": "3f269837-5cfc-426d-e8b6-534a9a84793d"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1.000e+00 3.006e+03 1.240e+02]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# training the model\n",
        "# collect the features 'x' and stack them into a matrix x\n",
        "X = np.zeros((len(train_x), 3))\n",
        "for i in range(len(train_x)):\n",
        "  X[i, :] = extract_features(train_x[i], freqs)\n",
        "\n",
        "  # training lables corresponding to  x\n",
        "  Y = train_y\n",
        "  # apply gradient descent\n",
        "  # there values are predefined\n",
        "  J, theta = gradientDescent(X, Y, np.zeros((3,1)), 1e-9, 1500)"
      ],
      "metadata": {
        "id": "u3BRBX2fZFWa"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_tweet(tweet, freqs, theta):\n",
        "  x = extract_features(tweet, freqs)\n",
        "  y_pred = sigmoid(np.dot(x, theta))\n",
        "  return y_pred\n",
        "  "
      ],
      "metadata": {
        "id": "pYnVvD_JabuQ"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_logistic_regression(test_x, test_y, freqs, theta):\n",
        "  y_hat = []\n",
        "  for tweet in test_x:\n",
        "    y_pred = predict_tweet(tweet, freqs, theta)\n",
        "    if y_pred>0.5:\n",
        "      y_hat.append(1)\n",
        "    else:\n",
        "      y_hat.append(0)\n",
        "  accuracy = (y_hat == np.squeeze(test_y)).sum() / len(test_x)"
      ],
      "metadata": {
        "id": "NiCHUbVbdMRq"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tmp_accuracy = test_logistic_regression(test_x, test_y, freqs, theta)\n",
        "print(tmp_accuracy)"
      ],
      "metadata": {
        "id": "CXjLkzvCe14v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c751cd3e-a8f7-4899-cdec-1df0c8f87799"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def pre(sentence):\n",
        "  yhat = predict_tweet(sentence, freqs, theta)\n",
        "  if yhat > 0.5:\n",
        "    return 'Positive Sentiment'\n",
        "  elif yhat==0:\n",
        "    return 'Neutral sentiment'\n",
        "  else:\n",
        "    return 'Negative Sentiment'"
      ],
      "metadata": {
        "id": "lPWMgmrmfIen"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "my_tweet = 'It is so hot today but it is the perfect day for a beach party'\n",
        "res = pre(my_tweet)\n",
        "print(res)"
      ],
      "metadata": {
        "id": "HLKmVfWSffpv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b22b4a80-d6c3-4ec2-dd6f-0ef362d31181"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Positive Sentiment\n"
          ]
        }
      ]
    }
  ]
}